{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quHwuvnL_N9o"
   },
   "source": [
    "# Project 1: Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JWfOd3AVO9J"
   },
   "source": [
    "## Task 0: Getting Started\n",
    "\n",
    "Read the getting started guide titled **\"Python for Deep Learning\"** and get familiar with Python and PyTorch. Read the provided code below and get familiar with the commands and their parameters to understand what the code is trying to do. We recommend to spend a fair amount of time to understand all the different parts of the code. This understanding will be important for this and future projects.\n",
    "\n",
    "The goal of this project is to implement the *“Hello World!”* program of deep learning: designing and training a network that performs image classification. The dataset we will be using is CIFAR10 which is a large set of images that are classified into 10 classes (airplane, bird, cat, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wgsyd2YsVO9L"
   },
   "source": [
    "## Task 1:  Data Loading (10 points)\n",
    "Complete the **DataLoader** below which we will use to load images of the cifar10 dataset provided by torchvision. Your task is to normalize it by shifting and scaling it by a factor of 0.5. For the training set, introduce random transformations (e.g. flips) for data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EtxYeHjRVO9S",
    "outputId": "210857dc-3b3e-4bd2-cb61-ae1e13877715"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "print(torch.__version__)\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "# Data augmentation, tensor conversion and normalization for training\n",
    "# Just normalization and tensor conversion for testing\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "      # TODO: Task 1\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "     # TODO: Task 1\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Download (if not downloaded before) & Load CIFAR10\n",
    "torch.random.manual_seed(0)\n",
    "image_datasets = {x: torchvision.datasets.CIFAR10(root='./data', train=(x=='train'), download=True, transform=data_transforms[x]) for x in ['train', 'test']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=(x=='train'), num_workers=4) for x in ['train', 'test']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "# Ship to GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"The classes found in CIFAR-10 are: {class_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uS6cR4RhVO9U"
   },
   "source": [
    "### Visualize a few images\n",
    "\n",
    "Let’s visualize a few training images so as to understand the data augmentations. The results should look like:\n",
    "\n",
    "<img src=\"https://i.imgur.com/Sa6l1go.png\" width=\"400\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xXSA5DDBVO9V"
   },
   "outputs": [],
   "source": [
    "# TODO Task 1:  Run this cell and try to understand the output of each step\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.5, 0.5, 0.5])\n",
    "    std = np.array([0.5, 0.5, 0.5])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmMMSK0TVO9L"
   },
   "source": [
    "## Task 2: Basic Networks (20 points)\n",
    "1. Create a Fully connected Network (FcNet) using the following layers in the Jupyter Notebook (use the non-linearities wherever necessary):\n",
    "```\n",
    "FcNet(\n",
    "  (fc1): Linear(in_features=3072, out_features=1024, bias=True)\n",
    "  (fc2): Linear(in_features=1024, out_features=400, bias=True)\n",
    "  (fc3): Linear(in_features=400, out_features=84, bias=True)\n",
    "  (fc4): Linear(in_features=84, out_features=10, bias=True)\n",
    ")\n",
    "```\n",
    "Train the FcNet for **3** epoches and record the training time and accuracy in your final report.\n",
    "\n",
    "2. Create a Convolutional Network (ConvNet) using the following layers in the Jupyter Notebook (use the non-linearities wherever necessary):\n",
    "```\n",
    "ConvNet(\n",
    "  (conv): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
    "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "  (conv): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
    "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
    "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
    "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
    ")\n",
    "```\n",
    "Train the ConvNet for **3** epoches and record the training time and accuracy in your final report. Note: You can reuse the conv layers to match the in_features of fc1. \n",
    "\n",
    "*Use the default SGD optimizer ( lr=0.001, momentum=0.9) for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1sKXg8fSVO9X"
   },
   "source": [
    "### Model training code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A_Y2cgPEVO9X"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=25, save_path='saved_weight.pth'):\n",
    "    since = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train']:\n",
    "            if phase == 'train': model.train()  # Set model to training mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "    print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wrQFn-EzBKmA"
   },
   "source": [
    "### Model test code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ttChDlePBKmB"
   },
   "outputs": [],
   "source": [
    "def test_model(model, load_path='saved_weight.pth'):    \n",
    "    # load the model weights\n",
    "    model.load_state_dict(torch.load(load_path))\n",
    "    \n",
    "    since = time.time()\n",
    "\n",
    "    for phase in ['test']:\n",
    "        if phase == 'test':\n",
    "            model.eval()   # Set model to evaluate mode\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # Iterate over data.\n",
    "        for inputs, labels in dataloaders[phase]:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "           \n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # statistics\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "        print('{} Acc: {:.4f}'.format(phase, epoch_acc))\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Testing complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tX6I8cqXFDMX"
   },
   "source": [
    "### 1) FC Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rpompN92VO9d"
   },
   "outputs": [],
   "source": [
    "# 1) Define a Fully Connected Neural Network\n",
    "# Please advise the Pytorch Documentation and use the appropiate calls\n",
    "\n",
    "class FcNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FcNet, self).__init__()\n",
    "        # TODO Task 2:  Define the layers \n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO Task 2:  Define the forward pass\n",
    "        \n",
    "        return x\n",
    "\n",
    "model_ft = FcNet() #Define the model\n",
    "model_ft = model_ft.to(device) \n",
    "print(model_ft)\n",
    "\n",
    "# TODO Task 2:  Define loss criterion - cross entropy loss\n",
    "# TODO Task 2:  Define Optimizer\n",
    "# TODO Task 2:  Train the model\n",
    "# TODO Task 2:  Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kFQdcJaKFF8y"
   },
   "source": [
    "### 2) CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ma36XwVfVO9h"
   },
   "outputs": [],
   "source": [
    "# 2) Define a Convolutional Neural Network\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # TODO Task 2:  Define the CNN layers \n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO Task 2:  Define the forward pass\n",
    "        \n",
    "        return x\n",
    "\n",
    "model_ft = ConvNet() #Define the model\n",
    "model_ft = model_ft.to(device)\n",
    "print(model_ft)\n",
    "# TODO Task 2:  Define loss criterion - cross entropy loss\n",
    "# TODO Task 2:  Define Optimizer\n",
    "# TODO Task 2:  Train the model\n",
    "# TODO Task 2:  Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NMAIB0f8VO9M"
   },
   "source": [
    "## Task 3.A: Design Your Network (30 points)\n",
    "Define your own Convolutional Network (MyNet) based on the [ResNet paper](https://arxiv.org/pdf/1512.03385.pdf) architecture (see Sec. 4.2 for the original architecture used). Here we will experiment with different configurations. Add following modifications and train the Network for **25** epoches. Keep the best settings for each step (for each step, record the training accuracy of the last epoch and test accuracy in your report):\n",
    "\n",
    "- Modify the number of ResNet blocks per layer: For Simplicity, implement a three-layered ResNet architecture. For each layer, try 1 , 2 and 3 number of ResNet blocks (3 configurations in total). You can choose any of the downsampling methods to match the tensor sizes wherever necessary. Use 2D average pooling layer before applying the final linear layer. For the three layers keep the number of filters 16, 32 and 64 respectively. Follow the ResNet paper to select the kernel size, paddings, optimizer/learning rate, strides, activations and **Batch Normalization** (select a suitable batch size) layers for this task. Print the model summary of the selected model.\n",
    "\n",
    "#### *Bonus Points: Define a validation set within the training set to monitor underfitting/overfitting after every epoch for each task. (Hint modify dataloaders and/or train_model function) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design Your Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3.A: Configuration 1\n",
    "\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        # TODO Task 3: Design Your Network\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO Task 3: Design Your Network\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3.A: Configuration 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3.A: Configuration 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.B: Design Your Network (10 points)\n",
    "Using your best network/model from Task 3.A, please do the following modifications:\n",
    "\n",
    "- Use Dropout: Toggle **Dropout** in fully connected layers. Does it improve the validation/test accuracy and/or avoid overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3.B: Using Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8E_4eLwBKmD"
   },
   "source": [
    "## Task 4: The Optimizer (20 points)\n",
    "Keeping the best settings of Task 4, try 2 different optimizers (SGD and ADAM) with 3 different learning rates (0.01, 0.1, 1.) . Keep the other parameters as default. Plot the loss curves ( Training step vs Training loss ) for the 6 cases (Hint: Modify the train_model fuction). How does the learning rate affect the training?\n",
    "\n",
    "#### *Bonus Points: Define a validation set within the training set to examine the best model among the above cases. (Hint modify dataloaders and/or train_model function) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PpRAJHrtVO9o"
   },
   "outputs": [],
   "source": [
    "# Define a Convolutional Neural Network\n",
    "class MyFinalNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        # TODO Task 3: Design Your Network\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO Task 3: Design Your Network\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "77S-thkZVO9q"
   },
   "outputs": [],
   "source": [
    "model_ft = MyNet()\n",
    "model_ft = model_ft.to(device)\n",
    "# TODO:  Define loss criterion - cross entropy loss\n",
    "# TODO Task 4: The Optimizer\n",
    "## Train and evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l1BjghDmBKmE"
   },
   "source": [
    "### Display model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "praSRn54BKmE"
   },
   "outputs": [],
   "source": [
    "## Display model predictions\n",
    "## Generic function to display predictions for a few images\n",
    "\n",
    "def display_predictions(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['test']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6buAMF5CBKmE"
   },
   "outputs": [],
   "source": [
    "# TODO Diplay your best model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-A_mLSoVO9O"
   },
   "source": [
    "## Task 5: Feature Visualization (5 points)\n",
    "Visualize feature maps of the first and the last convolutional layer of your final network using **cifar_example.jpg** as input image. Show the visualization in the report.\n",
    "\n",
    "#### First layer activations\n",
    "<img src=\"https://i.imgur.com/kGB9AuP.png\" width=\"400\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TsbbsIGKVO9P"
   },
   "source": [
    "#### Last layer activations\n",
    "\n",
    "<img src=\"https://i.imgur.com/qelH05X.png\" width=\"400\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IhQxWX8RVO91"
   },
   "outputs": [],
   "source": [
    "#Task 5: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gNX3eVEyVO94"
   },
   "outputs": [],
   "source": [
    "def transfer_single_img_to_tensor(img_path):\n",
    "    im = Image.open(img_path)\n",
    "    img = np.asarray(im)/255\n",
    "    mean = np.array([0.5, 0.5, 0.5])\n",
    "    std = np.array([0.5, 0.5, 0.5])\n",
    "    \n",
    "    inp = (img - mean) / std\n",
    "    inp = np.asarray(inp, dtype=np.float32)\n",
    "    inp = inp.transpose((2, 0, 1))\n",
    "    inp = np.expand_dims(inp, axis=0)\n",
    "    inp = torch.from_numpy(inp, )\n",
    "    inputs = inp.to(device)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m4Qy8s4BVO9_"
   },
   "outputs": [],
   "source": [
    "def feature_imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.detach().numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.5, 0.5, 0.5])\n",
    "    std = np.array([0.5, 0.5, 0.5])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L0AqVUu9VO97"
   },
   "outputs": [],
   "source": [
    "inputs = transfer_single_img_to_tensor('example_imgs/cifar_example.jpg') # Loads an image and normalizes it\n",
    "model_ft.eval()\n",
    "with torch.no_grad():\n",
    "   # TODO: Retrive the first and the last layer feature maps of your best model. (Hint: Move back to CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ofvGE8-VO-B"
   },
   "outputs": [],
   "source": [
    "# Visualize the feature maps\n",
    "out = torchvision.utils.make_grid(# TODO: feaure map 1)\n",
    "feature_imshow(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Mo1xtSzVO-E"
   },
   "outputs": [],
   "source": [
    "out = torchvision.utils.make_grid(# TODO: feaure map 2)\n",
    "feature_imshow(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Weight Visualization (5 points)\n",
    "Visualize weights of convolutional layers of your final network. Show the visualization in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Task 6\n",
    "# Hint: \n",
    "# 1) What is the size of each weight (filter) tensor?\n",
    "# 2) Normalize weight values to [0, 1]\n",
    "# 3) Each subfigure should be of size [kernel_size, kernel_size]\n",
    "# 4) How many subfigures in total?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Project1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
